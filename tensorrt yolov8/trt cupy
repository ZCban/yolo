import cv2
import numpy as np
import tensorrt as trt
import cupy as cp
import time
import bettercam
from win32api import GetSystemMetrics

# Configurazione
screenshot = 350
countfps = True
movespeed = 2
visual = False
fovx = 2.2
fovy = 1.2
activationkey = 0x05
modelname = 'model.trt'  # Modello TensorRT
fpslimit = 0

# Ottenere la risoluzione dello schermo dinamicamente
screen_width = GetSystemMetrics(0)
screen_height = GetSystemMetrics(1)

# Configurazione bettercam
left, top = (screen_width - screenshot) // 2, (screen_height - screenshot) // 2
right, bottom = left + screenshot, top + screenshot
region = (left, top, right, bottom)
cam = bettercam.create(output_idx=0, output_color="BGR")
cam.start(region=region, video_mode=True, target_fps=fpslimit)
center = screenshot / 2

# TensorRT YOLOv8 Engine
class Yolov8TensorRTEngine:
    def __init__(self, engine_path):
        self.mean = None
        self.std = None

        self.class_num = 3
        self.class_name_list = ['ally', 'enemy', 'bot']

        logger = trt.Logger(trt.Logger.WARNING)
        runtime = trt.Runtime(logger)
        trt.init_libnvinfer_plugins(logger, '')
        with open(engine_path, "rb") as f:
            serialized_engine = f.read()
        engine = runtime.deserialize_cuda_engine(serialized_engine)
        self.imgsz = engine.get_binding_shape(0)[2:]
        self.context = engine.create_execution_context()
        self.inputs, self.outputs, self.bindings = [], [], []
        for binding in engine:
            size = trt.volume(engine.get_binding_shape(binding))
            dtype = trt.nptype(engine.get_binding_dtype(binding))
            device_mem = cp.cuda.alloc(size * dtype.itemsize)
            self.bindings.append(int(device_mem.ptr))
            if engine.binding_is_input(binding):
                self.inputs.append({'device': device_mem})
            else:
                self.outputs.append({'device': device_mem})

    def _infer(self, img):
        img = cp.asarray(img)
        cp.cuda.runtime.memcpy(dst=self.inputs[0]['device'].ptr, src=img.data.ptr, size=img.nbytes, kind=cp.cuda.runtime.memcpyHostToDevice)
        self.context.execute_v2(bindings=self.bindings)
        output = []
        for out in self.outputs:
            host_output = cp.empty(out['device'].size, dtype=cp.float32)
            cp.cuda.runtime.memcpy(dst=host_output.data.ptr, src=out['device'].ptr, size=host_output.nbytes, kind=cp.cuda.runtime.memcpyDeviceToHost)
            output.append(host_output)
        return [o.get() for o in output]

    def inference(self, origin_img, conf=0.5, end2end=False):
        img, ratio = self.preproc(origin_img, self.imgsz, self.mean, self.std)
        data = self._infer(img)
        if end2end:
            num, final_boxes, final_scores, final_cls_inds = data
            final_boxes = np.reshape(final_boxes / ratio, (-1, 4))
            dets = np.concatenate([final_boxes[:num[0]], np.array(final_scores)[:num[0]].reshape(-1, 1),
                                   np.array(final_cls_inds)[:num[0]].reshape(-1, 1)], axis=-1)
        else:
            predictions = np.reshape(data, (1, -1, int(5 + self.class_num)))[0]
            dets = self.postprocess(predictions, ratio)

        targets = []
        if dets is not None:
            final_boxes, final_scores, final_cls_inds = dets[:, :4], dets[:, 4], dets[:, 5]
            class_names = self.class_name_list
            boxes = final_boxes[final_scores > conf]
            classes = final_cls_inds[final_scores > conf]

            for box, cls_idx in zip(boxes, classes):
                x1, y1, x2, y2 = map(int, box)
                class_name = class_names[int(cls_idx)]
                target_info = [class_name, (x1, y1), (x2, y2)]
                targets.append(target_info)
        return targets

    def postprocess(self, predictions, ratio):
        boxes = predictions[:, :4]
        scores = predictions[:, 4:5] * predictions[:, 5:]
        boxes_xyxy = np.ones_like(boxes)
        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2.
        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2.
        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2.
        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2.
        boxes_xyxy /= ratio
        dets = self.multiclass_nms(boxes_xyxy, scores, nms_thr=0.45, score_thr=0.1)
        return dets

    @staticmethod
    def nms(boxes, scores, nms_thr):
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]

        areas = (x2 - x1 + 1) * (y2 - y1 + 1)
        order = scores.argsort()[::-1]

        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])

            w = np.maximum(0.0, xx2 - xx1 + 1)
            h = np.maximum(0.0, yy2 - yy1 + 1)
            inter = w * h
            ovr = inter / (areas[i] + areas[order[1:]] - inter)

            inds = np.where(ovr <= nms_thr)[0]
            order = order[inds + 1]

        return keep

    def multiclass_nms(self, boxes, scores, nms_thr, score_thr):
        final_dets = []
        num_classes = scores.shape[1]
        for cls_ind in range(num_classes):
            cls_scores = scores[:, cls_ind]
            valid_score_mask = cls_scores > score_thr
            if valid_score_mask.sum() == 0:
                continue
            else:
                valid_scores = cls_scores[valid_score_mask]
                valid_boxes = boxes[valid_score_mask]
                keep = self.nms(valid_boxes, valid_scores, nms_thr)
                if len(keep) > 0:
                    cls_inds = np.ones((len(keep), 1)) * cls_ind
                    dets = np.concatenate([valid_boxes[keep], valid_scores[keep, None], cls_inds], 1)
                    final_dets.append(dets)
        if len(final_dets) == 0:
            return None
        return np.concatenate(final_dets, 0)

    @staticmethod
    def preproc(image, input_size, mean, std, swap=(2, 0, 1)):
        if len(image.shape) == 3:
            padded_img = np.ones((input_size[0], input_size[1], 3)) * 114.0
        else:
            padded_img = np.ones(input_size) * 114.0
        img = np.array(image)
        r = min(input_size[0] / img.shape[0], input_size[1] / img.shape[1])
        resized_img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)), interpolation=cv2.INTER_LINEAR).astype(np.float32)
        padded_img[:int(img.shape[0] * r), :int(img.shape[1] * r)] = resized_img
        padded_img = padded_img[:, :, ::-1]
        padded_img /= 255.0
        if mean is not None:
            padded_img -= mean
        if std is not None:
            padded_img /= std
        padded_img = padded_img.transpose(swap)
        padded_img = np.ascontiguousarray(padded_img, dtype=np.float32)
        return padded_img, r

class TensorRTModel:
    def __init__(self, trt_model, confidence_thres, iou_thres):
        self.predict_model = Yolov8TensorRTEngine(trt_model)
        self.confidence_thres = confidence_thres
        self.iou_thres = iou_thres

    def __call__(self, image):
        results = self.predict_model.inference(image, conf=self.confidence_thres)
        return results

    def draw_detections(self, img, class_name, box):
        x1, y1, x2, y2 = box
        color = (0, 255, 0)
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        label = f"{class_name}"
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

    def update_fps(self, start_time):
        self.frame_count += 1
        elapsed_time = time.time() - start_time
        if elapsed_time > 1:
            self.fps = self.frame_count / elapsed_time
            self.frame_count = 0
            start_time = time.time()
            print(self.fps)

# Inizializzare il modello TensorRT
model = TensorRTModel(modelname, 0.52, 0.55)

while True:
    img = cam.get_latest_frame()
    results = model(img)
    targets = []

    for class_name, (x1, y1), (x2, y2) in results:
        target_x = int((x1 + x2) / 2)
        target_y = int((y1 + y2) / 2)
        target_height = int(y2 - y1)
        targets.append((target_x, target_y, target_height))

    targets_array = np.array(targets)

    if len(targets_array) > 0:
        distances = np.linalg.norm(targets_array[:, :2] - center, axis=1)
        nearest_index = np.argmin(distances)
        nearest_distance = distances[nearest_index]
        nearest_target = targets[nearest_index]
        delta_x = int(nearest_target[0] + center)
        delta_y = int(nearest_target[1] + center)
        delta_y -= int(nearest_target[2] / 2.8)

    if visual:
        for class_name, (x1, y1), (x2, y2) in results:
            model.draw_detections(img, class_name, (x1, y1, x2, y2))
        cv2.imshow("Detected Objects", img)
        cv2.waitKey(1)

    if countfps:
        model.update_fps(time.time())

cv2.destroyAllWindows()
cam.stop()
